# Data Scientist

## About me

Physicist Engineer and Master's in Data Science, specialized in the analysis and processing of large volumes of data using advanced Machine Learning, Deep Learning, and Big Data techniques. I seek to participate in challenging projects in a dynamic and collaborative environment that promotes innovation. I am committed to driving strategic decision-making by transforming complex data into actionable and valuable insights

#### Technical Skills: Python, R, SQL, C, C++, Azure, Machine Learing, Deep Learning, Big Data

## Education
- M.S., Data Science | UOC Open University of Catalonia (_Feb 2024_)								       		
- M.S., Engineering Physics	| University of Cauca (_Dec 2017_)
- B.S., Engineering Physics | University of Cauca (_Aug 2011_)

## Professional Experience
**Data Scientist @ Independent (_June 2022 - Present_)**
- Developed a Python-based framework using vectorbt and the RIPPER algorithm.
- Integrated modules for design, backtesting, and robustness testing of algorithmic trading strategies.

## Projects
### Machine learning techniques applied to predict potential buyers in an e-commerce platform for business products in Colombia
[Publication](https://github.com/jhontd03/PredictionCustomer)

In a context where business information is essential, anticipating who will become customers is crucial for business strategy. To tackle this challenge, I used various machine learning techniques and the CRISP-DM methodology, focusing my research on five key phases:

- Understand business challenges and define objectives for prediction and retention.
- Analyze data quality by considering various sources.
- Prepare the data through cleaning and transformation.
- Implement machine learning techniques to build predictive models.
- Evaluate performance and compare the effectiveness of the models.

Machine Learning Models and Techniques Used:

- Sampling: Applied to balance the classes of the target variable. I tested different sampling techniques to select the best classification models.
- Ensemble Models: Used to improve the accuracy of predictions. Includes Random Forest, Gradient Boosting, and XGBoost.
- Recursive Feature Elimination (RFE): To select the most relevant variables, optimizing model performance.
- Cost-sensitive Learning (CSL): Implemented to address class imbalance issues, maximizing the effectiveness of predictive models.
- Voting: Technique used to combine the best models, resulting in a robust and accurate final model.
    
![Prediction Customer](/assets/img/eeg_band_discovery.jpeg)

### Decoding Physical and Cognitive Impacts of Particulate Matter Concentrations at Ultra-Fine Scales
[Publication](https://www.mdpi.com/1424-8220/22/11/4240)

Used **Matlab** to train over 100 machine learning models which estimated particulate matter concentrations based on a suite of over 300 biometric variables. We found biometric variables can be used to accurately estimate particulate matter concentrations at ultra-fine spatial scales with high fidelity (r2 = 0.91) and that smaller particles are better estimated than larger ones. Inferring environmental conditions solely from biometric measurements allows us to disentangle key interactions between the environment and the body.

![Bike Study](/assets/img/bike_study.jpeg)
